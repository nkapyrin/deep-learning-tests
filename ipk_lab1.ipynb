{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nТренируем классификатор\n=====================\n\nВ этой работе мы воспользуемся знаниями о построении нейронных сетей, использовании оптимизаторов и функций потери.\n\nИ коснёмся проблемы, откуда же нам брать данные.\n\nК вопросу о данных\n----------------\n\nЕсли не хотеть сильно усложнить себе работу, если входными данными являются текст, изображения, аудио и видео,\nлегче всего пользоваться стандартными модулями python, которые загружают данные в матрицу numpy.\nПосле этого можно преобразовать этот массив в ``torch.*Tensor``.\n\n-  Для работы с изображениями существуют пакеты Pillow, OpenCV\n-  В том, что касается аудио, есть пакеты scipy и librosa\n-  Что касается текста, с ним работают либо при помощи простых загрузчиков Python или Cython, или NLTK и SpaCy\n\nСпециально для задач машинного зрения, разработчики *torch* , создали пакет\n``torchvision``, который включает загрузчики для большинства известных датасетов, например \nImagenet, CIFAR10, MNIST, и т.д. и инструментов для трансформации изображений, а именно: \n``torchvision.datasets`` и ``torch.utils.data.DataLoader``.\n\n\nВ этом примере мы используем датасет CIFAR10.\nВ нём представлены классы: \u2018самолёт\u2019, \u2018автомобиль\u2019, \u2018птица\u2019, \u2018кот\u2019, \u2018олень\u2019,\n\u2018собака\u2019, \u2018лягушка\u2019, \u2018лошадь\u2019, \u2018корабль\u2019, \u2018грузовик\u2019. Изображения CIFAR-10 имеют размер \nsize 3x32x32, т.е. это 3-канальные изображения по 32x32 пикселя.\n\n\nОбучить классификатор изображений\n----------------------------\n\nДля этого реализуем следующие шаги:\n\n1. Загрузить и *нормализовать* датасеты CIFAR10, тренировнчный и проверочный, с помощью\n   ``torchvision``\n2. Задать конволюционную нейронную сеть\n3. Определить функцию потерь\n4. Натренировать сеть на тренировочных данных\n5. Протестировать сеть на данных\n\n### Загрузка и нормализация CIFAR10\n\nИспользуя ``torchvision``, загрузить CIFAR10 можно так.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "!pip install torch\n!pip install import torchvision\nimport torchvision\nimport torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "На выходе torchvision создаёт изображения типа PILImage со значениями в пределах [0, 1].\nМы переводим их в тензоры в нормализованном пространстве [-1, 1].\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                        download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n                                          shuffle=True, num_workers=2)\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False,\n                                       download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=4,\n                                         shuffle=False, num_workers=2)\n\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Изобразим несколько тренировочных изображений, просто для показа.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\n\n# functions to show an image\n\n\ndef imshow(img):\n    img = img / 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n\n\n# get some random training images\ndataiter = iter(trainloader)\nimages, labels = dataiter.next()\n\n# show images\nimshow(torchvision.utils.make_grid(images))\n# print labels\nprint(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Определим CNN (конволюционную нейросеть)\n\nЭта сеть умеет работать с изображениями у которых 3 цветовых канала.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n\nnet = Net()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Определим функцию потерь и оптимизатор\n\nИспользуем перекрёстную энтропию и стохастический градиентный спуск (SGD) с инерцией.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Обучаем нейронную сеть\n\nЗдесь происходит всё самое важное, хотя мы и просто проходимся по итератору который перебирает данные, и подаём входы в нейронную сеть, а потом оптимизируем.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        # get the inputs\n        inputs, labels = data\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % 2000 == 1999:    # print every 2000 mini-batches\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss / 2000))\n            running_loss = 0.0\n\nprint('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Протестировать обучение на тестовых данных\n\nМы обучали нейронную сеть путём двух проходов по всем тренировочным данным.\nСамое время проверить, обучилась ли сеть хотя бы чему-нибудь.\n\nПроверкой будет служить предсказание метки класса которую выдаёт нейронная сеть, и проверкой относительно *ground-truth*. Если предсказание сбылось, добавляем его в список хороших образцов.\n\nПервый шаг. Покажем изображение из тестовой выборки.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataiter = iter(testloader)\nimages, labels = dataiter.next()\n\n# print images\nimshow(torchvision.utils.make_grid(images))\nprint('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Есть. Теперь посмотрим, что нейронная сеть думает об этих объектах:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "outputs = net(images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Выведем уверенность (энергию) каждого класса.\nЧем больше *энергия*, тем увереннее сеть относится \n к факту принадлежности изображения к конкретному классу.\nТак что берём индекс наиболее уверенного прогноза:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "_, predicted = torch.max(outputs, 1)\n\nprint('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n                              for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Результат обнадёживает.\n\nПосмотрим, как сеть тестируется на всём наборе данных.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "correct = 0\ntotal = 0\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        outputs = net(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the 10000 test images: %d %%' % (\n    100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Всё что больше 10% (принимать случайное решение относительно одного из 10 классов) -- нас вполне устраивает.\nПохоже, что сеть чему-то обучилась.\n\nПосмотрим, какие класса предсказываются хорошо, а какие не очень:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class_correct = list(0. for i in range(10))\nclass_total = list(0. for i in range(10))\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        outputs = net(images)\n        _, predicted = torch.max(outputs, 1)\n        c = (predicted == labels).squeeze()\n        for i in range(4):\n            label = labels[i]\n            class_correct[label] += c[i].item()\n            class_total[label] += 1\n\n\nfor i in range(10):\n    print('Accuracy of %5s : %2d %%' % (\n        classes[i], 100 * class_correct[i] / class_total[i]))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
